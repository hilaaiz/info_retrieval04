The Secretary of State knows that leading AI developers are expected imminently to release new, more sophisticated AI models.
Can she confirm that our AI Safety Institute has had access to those models, as was agreed at Bletchley Park?
Is it the case that the developers have made changes to their models where they have been requested by the institute?
I know that my right hon.
Friend shares my passion and enthusiasm for this topic, as well as a desire to make sure we grip the risk.
Our institute is  the first in the world to be doing pre and post-deployment testing, in line with the agreement we made at Bletchley Park.
I cannot get into the specifics of which models we are testing, as I am sure he will understand, as that is highly commercially sensitive information, but I can assure him and the House that where risks are found, we expect relevant action to be taken.
The responsibility of developers is to ensure that their models are safe, but the Government are committed to holding them to account.
Does my right hon.
Friend agree that spreading best practice in this field is perhaps the most important thing?
For example, the health benefits of AI have already been mentioned, such as in the diagnosis of bowel cancer, and that is about promoting the health of the public at large.
Those things need to be pushed forward with urgency.
It is not enough just to try to slow things down and over-regulate.
I absolutely agree.
AI has the potential to be revolutionary, especially in areas such as healthcare.
That is why at the summit we announced a Â£100 million pot to accelerate some of our existing healthcare missions.
We are working hand in hand with the Department of Health and Social Care on this important topic.